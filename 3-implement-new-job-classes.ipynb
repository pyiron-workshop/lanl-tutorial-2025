{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ea92a74-de61-4b8c-9492-4dcabaf015c1",
   "metadata": {},
   "source": [
    "# Implement new pyiron jobs\n",
    "\n",
    "Author: [jan-janssen](https://jan-janssen.com)\n",
    "\n",
    "While the first two tutorials covered the use of existing simulation codes e.g. LAMMPS in pyiron and how multiple calculation can be combined in a workflow using the `GenericMasters` jobs like the `Murnaghan` to calculate energy volume curves, the implementation of new simulation codes and utilities is another strength of pyiron. To emphasise the application of pyiron beyond the scope of atomistic simulations, the pyiron project was split in two parts `pyiron_atomistics` for the atomistic simulation codes and utilities and `pyiron_base` for the general job management of pyiron which can be used to define your own job classes. \n",
    "\n",
    "In the following `pyiron_base` is used to demonstrate the implementation of two example jobs, the first one calling an external executable and the second calling a python function and representing it as pyiron job object. For each of two categories there are multiple slightly different variants how pyiron job objects can be defined. \n",
    "\n",
    "In analogy to the previous tutorials we enable the autocompletion for multiple levels using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b962977-29e2-43e7-9aaa-ef5542837d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.evaluation='unsafe'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958d958d-6e80-4a9b-95ea-201f02b85156",
   "metadata": {},
   "source": [
    "## External Executable\n",
    "While an increasing number of simulation codes provide Python bindings so they can be intergrated in a Python Function call, there are still a number of external executables one might want to integrate in a given workflow. For the example here the executable is the shell command:\n",
    "```\n",
    "cat input > output\n",
    "```\n",
    "It copies the content of the input file to the output file, still this command could be replaced with any other call of an external executable.\n",
    "\n",
    "### GenericJob\n",
    "Already the initial [pyiron paper](https://doi.org/10.1016/j.commatsci.2018.07.043) introduced the implementation of custom pyiron job objects in Appendix C. Here the code is slightly modified to be compatible with the recent version of `pyiron_base`. \n",
    "\n",
    "The `GenericJob` class as well as the `GenericParameters` class can both be imported from `pyiron_base`. In addition, the `os` module from the standard library is imported to define the path to the input and output files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb0fac53-cdbd-4286-9830-13bacd6c3747",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyiron_base import GenericJob, GenericParameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e72800d-334a-4561-b2e0-b5d1808ccc11",
   "metadata": {},
   "source": [
    "The job class `ToyJob` in this example is derived from the `GenericJob` class and defines four functions:\n",
    "* `write_input()` writes the input which based on the input stored in the `ToyJob` class to the working directory before the external executable is called. \n",
    "* `collect_output()` reads the input from the working directory and stores it in the HDF5 file of the job object.\n",
    "* `to_hdf()` stores the current instance of the `ToyJob` class in the HDF5 file.\n",
    "* `from_hdf()` reloads a previously stored instance of the `ToyJob` class from the HDF5 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f2db9a8-91e0-4080-bcab-79203432fde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyJob(GenericJob):\n",
    "    def __init__(self, project, job_name):\n",
    "        super(ToyJob, self).__init__(project, job_name)\n",
    "        self.input = ToyInput()\n",
    "        self.executable = \"cat input > output\"\n",
    "\n",
    "    def write_input(self):\n",
    "        self.input.write_file(\n",
    "            file_name=\"input\",\n",
    "            cwd=self.working_directory,\n",
    "        )\n",
    "\n",
    "    def collect_output(self):\n",
    "        file = os.path.join(self.working_directory, \"output\")\n",
    "        with open(file) as f:\n",
    "            line = f.readlines()[0]\n",
    "            energy = float(line.split()[1])\n",
    "        with self.project_hdf5.open(\"output/generic\") as h5out:\n",
    "            h5out[\"energy_tot\"] = energy\n",
    "\n",
    "    def to_hdf(self, hdf=None, group_name=None):\n",
    "        super(ToyJob, self).to_hdf(\n",
    "            hdf=hdf,\n",
    "            group_name=group_name\n",
    "        )\n",
    "        with self.project_hdf5.open(\"input\") as h5in:\n",
    "            self.input.to_hdf(h5in)\n",
    "\n",
    "    def from_hdf(self, hdf=None, group_name=None):\n",
    "        super(ToyJob, self).from_hdf(\n",
    "            hdf=hdf,\n",
    "            group_name=group_name,\n",
    "        )\n",
    "        with self.project_hdf5.open(\"input\") as h5in:\n",
    "            self.input.from_hdf(h5in)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d711608-e58e-410d-b465-a0e96a8b913e",
   "metadata": {},
   "source": [
    "In addtion, to the `ToyJob` class we also define the `ToyInput` class derived from the `GenericParameters`. This class is primarily used to define the default parameters of the `ToyJob` class and simplifies the writing of the input files in the `write_input()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ae3d263-003a-498f-83f8-b0f18d167fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyInput(GenericParameters):\n",
    "    def __init__(self, input_file_name=None):\n",
    "        super(ToyInput, self).__init__(\n",
    "            input_file_name=input_file_name,\n",
    "            table_name=\"input\"\n",
    "        )\n",
    "    \n",
    "    def load_default(self):\n",
    "        self.load_string(\"input_energy 100\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2fcead-b19b-459b-8f3b-3d9e079ea9e9",
   "metadata": {},
   "source": [
    "Following the definition of the two classes `ToyJob` and `ToyInput` we can use the `ToyJob` class in analogy to all the other pyiron job classes. To demonstrate the functionality of the `ToyJob` class we do a simple test calculation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9437343-005a-45f5-8b58-33012afd944c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiron_base import Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ca67e1c-5bd0-4de8-8279-4320cdaf4a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = Project('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f64d389-561c-45b5-a8e5-cd1763a4dcbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02c0fdec9ef64aadb640f538c3ea11fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pr.remove_jobs(recursive=True, silently=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4938b1a7-feb6-4a08-90d4-f22e718a5d37",
   "metadata": {},
   "source": [
    "After the project is imported and a new project is created which does not contain any previous calculation the `ToyJob` class can be used in the `create_job()` function to create a corresponding pyiron job object. In addition, the `job_name` is provided to distinguish multiple jobs of the same type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3694b18a-c947-46fd-b921-349d01e31618",
   "metadata": {},
   "outputs": [],
   "source": [
    "job = pr.create_job(ToyJob, job_name=\"toy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747f94e6-94e6-4228-979c-821c3aa22405",
   "metadata": {},
   "source": [
    "By using the `GenericParameters` class as a basis for the `ToyInput` the input of the `ToyJob` is nicely rendered as pandas dataframe and can be modified just like the LAMMPS input in the previous examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f530a876-d92d-44ca-86ef-4e4eff7fbdab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameter</th>\n",
       "      <th>Value</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>input_energy</td>\n",
       "      <td>100</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Parameter Value Comment\n",
       "0  input_energy   100        "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job.input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca14e07-50a4-4e90-9ad0-f12d6d1cd937",
   "metadata": {},
   "source": [
    "After defining the input the job object is executed using the `run()` function and the output can be inspected using the `job.content` propoerty again in analogy to the LAMMPS job class in the previous tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55e02cce-7350-43ed-adc0-89ff075906b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The job toy was saved and received the ID: 160\n"
     ]
    }
   ],
   "source": [
    "job.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7447dc9-662f-4564-bb74-070748eb2eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job.content['output/generic/energy_tot']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93d7926-b8d2-44c0-aa47-4dc59cfc84eb",
   "metadata": {},
   "source": [
    "### Template Job\n",
    "One limitation of using the `GenericJob` class is the requirement for the user to define the `to_hdf()` and `from_hdf()` functions which handle the serialization and deserialization of the job class in the HDF5 files. As many jobs just use the same kind of standard input and output structures represented as a dictionary, the `TemplateJob` class defines more extensive defaults, so the user no longer has to define the `to_hdf()` and `from_hdf()` functions. Apart from this the `TemplateJob` class is based on the `GenericJob` class and behaves exactly the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73123fe3-516c-4dfc-9578-2410ec34c5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiron_base import TemplateJob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8bbf7a25-1932-4987-8005-c9a46a41be8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyTemplateJob(TemplateJob):\n",
    "    def __init__(self, project, job_name):\n",
    "        super(ToyTemplateJob, self).__init__(project, job_name)\n",
    "        self.executable = \"cat input > output\"\n",
    "\n",
    "    def write_input(self):\n",
    "        with open(os.path.join(self.working_directory, \"input\"), \"w\") as f:\n",
    "            f.write(str(job.input.energy))\n",
    "\n",
    "    def collect_output(self):\n",
    "        with open(os.path.join(self.working_directory, \"output\"), \"r\") as f:\n",
    "            self.output.energy = f.read()\n",
    "        self.to_hdf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f091e420-31d2-48c9-9660-5c3037e4a4d9",
   "metadata": {},
   "source": [
    "It is important to add the `to_hdf()` function call at the end of the `collect_output()` function to store the output after it was parsed, otherwise the output is lost. The usage in a project follows in analogy to the `GenericJob` class example above. \n",
    "\n",
    "Starting by defining a `Project` and removing the jobs in this project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d82f0db8-979e-43df-bd62-24b03d9f587d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = Project('testtemp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bcdd5473-2cdf-4f35-a5e4-861c53426e09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "590ee19b2a3d4e239656d2c064a75a73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pr.remove_jobs(recursive=True, silently=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1961ce6e-aaac-472c-8469-a369eb76f657",
   "metadata": {},
   "source": [
    "The `ToyTemplateJob` class can again be used to create pyiron job objects using the `create_job()` function of the project object. The input is assigned to the `job.input` property and afterwards the job is executed by calling the `run()` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5628ffba-f558-487d-8efb-e3818cec1508",
   "metadata": {},
   "outputs": [],
   "source": [
    "job = pr.create_job(ToyTemplateJob, job_name=\"toytemp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e87a800-c21b-4e6b-a497-11b54f3407c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "job.input.energy = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30d84d37-de01-4cba-86fa-879b9db0b2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The job toytemp was saved and received the ID: 161\n"
     ]
    }
   ],
   "source": [
    "job.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f222ec5-ca80-4d08-8497-180fa04659d4",
   "metadata": {},
   "source": [
    "After the successful execution the output is available in the `job.output` property just like it was set in the `collect_output()` function above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88dff6e3-5a23-4ac4-8865-39940057cd13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'100'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job.output.energy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9439c937-0e4d-4173-aef4-728671687dac",
   "metadata": {},
   "source": [
    "### For testing\n",
    "While defining job classes based on the `GenericJob` or `TemplateJob` class is commonly preferable for frequently used job types, pyiron also provides an simplified interface to dynamically define pyiron jobs during the run time. Again, a `write_input()` and `collect_output()` function are require to interface the pyiron framework to the external executable. \n",
    "\n",
    "It is important that the supported input parameters for the `write_input()` function are only `input_dict` and `working_directory` and for the `collect_output()` function just the `working_directory` and the `collect_output()` function should return a dictionary with the corresponding outputs. Any other function signature won't work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e3c7761-1eef-424c-b8fe-2c406219bcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_input(input_dict, working_directory):\n",
    "    with open(os.path.join(working_directory, \"input\"), \"w\") as f:\n",
    "        f.write(str(input_dict[\"energy\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1dc3da8a-6718-4ea6-8d23-07ee59126d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_output(working_directory):\n",
    "    with open(os.path.join(working_directory, \"output\"), \"r\") as f:\n",
    "        return {\n",
    "            \"energy\": f.read()\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3af42ba-b7dd-4235-b5e9-8335351a52a2",
   "metadata": {},
   "source": [
    "In analogy to the two previous examples a new project is defined and the existing jobs in this project are removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47bf4b9a-ddde-48df-9b66-fe6b1ced9265",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = Project('template')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "22f2ec9f-44a7-471c-a908-0ac5bac85339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3931d7942b904cae9304cbcbe1fdeea6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pr.remove_jobs(recursive=True, silently=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bebbbf-e8ea-4dee-9ab1-753894662edb",
   "metadata": {},
   "source": [
    "The process of creating a pyiron job class from the `write_input()` function and the `collect_output()` function is hidden in the `create_job_class()` function. This function takes both the `write_input()` function and the `collect_output()` function as an input in addition to a `class_name` to access the pyiron job class later on, a dictionary with default parameters `default_input_dict` and the external executable as string `executable_str`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b477018d-37ff-476d-95b1-5324441f398e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr.create_job_class(\n",
    "    class_name=\"ToyJob\",\n",
    "    write_input_funct=write_input,\n",
    "    collect_output_funct=collect_output,\n",
    "    default_input_dict={  # Default Parameter \n",
    "        \"energy\": 100.0, \n",
    "    },\n",
    "    executable_str=\"cat input > output\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5950b1e-d646-44b1-8e89-4734ce9343fc",
   "metadata": {},
   "source": [
    "After the pyiron job class is created using the `create_job_class()` function, the corresponding pyiron job class instances can be created using the `pr.create.job.<job class>()` function, by just providing the job name as an input parameter, in analogy to the LAMMPS class in the previous tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9b02145e-fec3-4d33-98c0-5656a5908439",
   "metadata": {},
   "outputs": [],
   "source": [
    "job = pr.create.job.ToyJob(job_name=\"toy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b40ea2-5cd6-4744-a297-0d24b14d75cd",
   "metadata": {},
   "source": [
    "Again the input is assigned to the pyiron job class using the input property, afterwards the job is executed by calling the `run()` function and finally the output can be inspected using the output property. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f9d2b395-7ffe-4636-abae-466efe17a2f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "energy": "100.0"
      },
      "text/html": [
       "<pre>DataContainer({\n",
       "  \"energy\": \"100.0\"\n",
       "})</pre>"
      ],
      "text/plain": [
       "DataContainer({'energy': 100.0})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0282b1c3-4bbf-4a5a-b027-0e3b32a0e0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The job toy was saved and received the ID: 162\n"
     ]
    }
   ],
   "source": [
    "job.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c36fd558-f269-4cb1-bdd7-c4a5df2202e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "energy": "'100.0'",
       "stdout": "''"
      },
      "text/html": [
       "<pre>DataContainer({\n",
       "  \"stdout\": \"''\",\n",
       "  \"energy\": \"'100.0'\"\n",
       "})</pre>"
      ],
      "text/plain": [
       "DataContainer({'stdout': '', 'energy': '100.0'})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job.output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab991542-2ba5-4302-a5a5-4b07361fb4ff",
   "metadata": {},
   "source": [
    "## Python Function\n",
    "An alternative to interfacing with external executables is integrating Python functions directly in pyiron by representing them as pyiron job objects. In this example this is demonstrated on a simple multiplication function. Still the multiplication function is just an example and commonly this approach is more useful for functions which need a long run time in the order of several minutes or even hours. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "670e0715-b19a-40b8-8b10-42e9c22b8b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculation(value):\n",
    "    return 2 * value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8433043-479e-4e2c-ac72-aeeaed6e102b",
   "metadata": {},
   "source": [
    "### Python Template Job\n",
    "Following the same idea as the `TemplateJob` the `PythonTemplateJob` provides a predefined pyiron job type to simplify the implementation of new job classes. It can again be imported directly from the `pyiron_base` module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e7718b4f-f89a-437d-8f1d-24550a88a39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiron_base import PythonTemplateJob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecb8778-6229-4d90-a6a3-2857e6f601a1",
   "metadata": {},
   "source": [
    "The `ToyPythonJob` class derived from the `PythonTemplateJob` needs primarily two functions the `__init__()` function to set the default input and the `run_static()` function which is executed when `run()` is called on the corresponding job object. This calls the python function, stores its output in the pyiron job object, sets the status of the pyiron job object to finished and finally serializes the pyiron job object in an HDF5 file.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80567105-a340-409c-96f7-3923e4e678c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c5332f9e-18e0-4441-b4c1-99ce61f361fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyPythonJob(PythonTemplateJob):\n",
    "    def __init__(self, project, job_name):\n",
    "        super().__init__(project, job_name) \n",
    "        self.input.value = None\n",
    "\n",
    "    def run_static(self):\n",
    "        self.output.result = calculation(self.input.value)\n",
    "        self.status.finished = True\n",
    "        self.to_hdf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7fe836-0c2e-49c7-ae6f-e7c3801d58ae",
   "metadata": {},
   "source": [
    "The user can afterwards interact with the `ToyPythonJob` class just like any other pyiron job class. Again a new project is created and then the pyiron job object is defined in this project, the input is set using the `job.input` property and afterwards the job is executed using the `run()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cfccb1dd-6168-4750-92ae-17608e200eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = Project('template')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8a96aa3d-dc14-4fbb-916a-d6ed64c31760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57e9ebeed07948b99527759e022ab2c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pr.remove_jobs(recursive=True, silently=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0da90df0-4efc-48e5-86ad-7f5a48a1be9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "job = pr.create_job(ToyPythonJob, job_name=\"toy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b5818df0-d69f-4c50-8073-2dbb12e6ed63",
   "metadata": {},
   "outputs": [],
   "source": [
    "job.input.value = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5e3f927a-a2f4-4d16-89b9-ff4ade0be31e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The job toy was saved and received the ID: 162\n"
     ]
    }
   ],
   "source": [
    "job.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f62c9c93-71b6-4613-8b16-2d474dcfb3a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "result": "10"
      },
      "text/html": [
       "<pre>DataContainer({\n",
       "  \"result\": \"10\"\n",
       "})</pre>"
      ],
      "text/plain": [
       "DataContainer({'result': 10})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0f92f734-2337-4cdc-8f9f-ff89740c3f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job.output.result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6347aaa8-8165-441f-a968-30984103af02",
   "metadata": {},
   "source": [
    "### Function Wrapper\n",
    "For testing python functions which might only be used in a given notebook, pyiron also providews a `wrap_python_function()` function in analogy to the `create_job_class()` function introduced above. The Python function is simply provided as an input to the `wrap_python_function()` function which then returns a job class object the user can interact with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9af85b52-7b62-45ca-999d-c81645094998",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculation(value):\n",
    "    return 2 * value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a5fd0518-e326-400e-87e6-154487e54dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = Project('wrapper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5f61f5cc-c761-4239-91eb-938352e6d960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6be329e3b28a4d41b2719021ff67d3a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pr.remove_jobs(recursive=True, silently=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "227832ac-f772-43f2-87bf-17227d9c5733",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_calc = pr.wrap_python_function(calculation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a31f233d-49ad-4eed-bc04-544bd0732225",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_calc.input.value = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a26170d4-443c-442b-9cc6-35cbcd1d3c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The job calculation_e3cd70ecfcd6595bfd3de99721d2e84c was saved and received the ID: 163\n"
     ]
    }
   ],
   "source": [
    "job_calc.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b0d6de3c-3baf-4693-a7f6-b1c52a238455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "result": "200"
      },
      "text/html": [
       "<pre>DataContainer({\n",
       "  \"result\": \"200\"\n",
       "})</pre>"
      ],
      "text/plain": [
       "DataContainer({'result': 200})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_calc.output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294182a8-3fac-4545-a23b-ae515b544e88",
   "metadata": {},
   "source": [
    "### Job decorator\n",
    "Finally, to follow the process of calling the `wrap_python_function()` can be simplified further with the `@job` decorator. This decorator can be applied on any Python function an creates the corresponding job class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aeb4670e-19f2-44bd-8565-dc49560dc0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiron_base import job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "89d096aa-4357-4b0c-be07-b4d5a8fe7506",
   "metadata": {},
   "outputs": [],
   "source": [
    "@job\n",
    "def calculation(value):\n",
    "    return 2 * value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "324725cf-0832-4ceb-8345-f19d0baa83eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = Project('decorator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "016a77e7-fd6b-4f3f-a551-88c67efbbe39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3193060e214f4922a86cbc67e87d2f1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pr.remove_jobs(recursive=True, silently=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7f22b438-74d7-48b0-a0e3-8d2823080c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = calculation(value=5, pyiron_project=pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8da875eb-447f-4b81-bc02-5042592f5a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The job calculation_dfd3af2444a4040a36ade2cc6f66b360 was saved and received the ID: 164\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.pull()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639c3ed5-feed-4be8-9a8b-793e2938670b",
   "metadata": {},
   "source": [
    "## Summary \n",
    "In summary, while pyiron was initially developed for atomistic simulation it now provides a number of ways to integrate additional executables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c95ed92-dd63-4672-8dcc-b5747f712f5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b49e51-d4f4-49b8-a186-a7ddb65f5faf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
